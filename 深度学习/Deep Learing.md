---
title: Deep Learing 
tags: 深度学习,算法
grammar_cjkRuby: true
---


## 深度学习：自动特种提取算法

## 机器学习的过程
机器学习（Machine Learning）是一门专门研究计算机怎样模拟或实现人类的学习行为，以获取新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能的学科。机器学习的一般过程为：

 - 数据采集 
 - 特征表达（人工 OR 算法）
 -  预测识别

![机器学习一般过程][1]

在机器学习过程中，特征表达是重中之重。

![enter description here][2]

**数据特征表达一般过程如下:**

 - 预处理(Preprocessing) 
 - 特征抽象(Feature extract) 
 - 特征选择(Feature selection)

良好的特征表达，对最终算法的准确性起了非常关键的作用，而且系统主要的计算和测试工作都耗在这一大部分。但，这块实际中一般都是人工完成的。靠**人工提取特征**。

截止现在，也出现了不少NB的特征（好的特征应具有不变性（大小、尺度和旋转等）和可区分性）：例如**Sift**的出现，是局部图像特征描述子研究领域一项里程碑式的工作。由于SIFT对尺度、旋转以及一定视角和光照变化等图像变化都具有不变性，并且SIFT具有很强的可区分性，的确让很多问题的解决变为可能。但它也不是万能的。

 然而，手工地选取特征是一件非常费力、启发式（需要专业知识）的方法，能不能选取好很大程度上靠经验和运气，而且它的调节需要大量的时间。既然手工选取特征不太好，那么能不能自动地学习一些特征呢？答案是能！**Deep Learning**就是用来干这个事情的，看它的一个别名UnsupervisedFeature Learning，就可以顾名思义了，Unsupervised的意思就是不要人参与特征的选取过程。

## 分级特征提取

### 生物学启发

> 扩展阅读：[大脑怎么“看见”世界的——视觉系统知多少][3]

1943年，心理学家W·Mcculloch和数理逻辑学家W·Pitts在分析、总结神经元基本特性的基础上首先提出神经元的数学模型。此模型沿用至今，并且直接影响着这一领域研究的进展。因而，他们两人可称为人工神经网络研究的先驱。

1945年冯·诺依曼领导的设计小组试制成功存储程序式电子计算机，标志着电子计算机时代的开始。1948年，他在研究工作中比较了人脑结构与存储程序式计算机的根本区别，提出了以简单神经元构成的再生自动机网络结构。但是，由于指令存储式计算机技术的发展非常迅速，迫使他放弃了神经网络研究的新途径，继续投身于指令存储式计算机技术的研究，并在此领域作出了巨大贡献。虽然，冯·诺依曼的名字是与普通计算机联系在一起的，但他也是人工神经网络研究的先驱之一。

50年代末，F·Rosenblatt设计制作了“感知机”，它是一种**多层的神经网络**。这项工作首次把人工神经网络的研究从理论探讨付诸工程实践。当时，世界上许多实验室仿效制作感知机，分别应用于文字识别、声音识别、声纳信号识别以及学习记忆问题的研究。然而，这次人工神经网络的研究高潮未能持续很久，许多人陆续放弃了这方面的研究工作，这是因为当时数字计算机的发展处于全盛时期，许多人误以为数字计算机可以解决人工智能、模式识别、专家系统等方面的一切问题，使感知机的工作得不到重视；其次，当时的电子技术工艺水平比较落后，主要的元件是电子管或晶体管，利用它们制作的神经网络体积庞大，价格昂贵，要制作在规模上与真实的神经网络相似是完全不可能的；另外，在1968年一本名为《感知机》的著作中指出线性感知机功能是有限的，它不能解决如异或这样的基本问题，而且多层网络还不能找到有效的计算方法，这些论点促使大批研究人员对于人工神经网络的前景失去信心。60年代末期，人工神经网络的研究进入了低潮。

另外，在60年代初期，Widrow提出了自适应线性元件网络，这是一种连续取值的线性加权求和阈值网络。后来，在此基础上发展了非线性多层自适应网络。当时，这些工作虽未标出神经网络的名称，而实际上就是一种人工神经网络模型。

随着人们对感知机兴趣的衰退，神经网络的研究沉寂了相当长的时间。80年代初期，模拟与数字混合的超大规模集成电路制作技术提高到新的水平，完全付诸实用化，此外，数字计算机的发展在若干应用领域遇到困难。这一背景预示，向人工神经网络寻求出路的时机已经成熟。美国的物理学家Hopfield于1982年和1984年在美国科学院院刊上发表了两篇关于人工神经网络研究的论文，引起了巨大的反响。人们重新认识到神经网络的威力以及付诸应用的现实性。随即，一大批学者和研究人员围绕着 Hopfield提出的方法展开了进一步的工作，形成了80年代中期以来人工神经网络的研究热潮。

Hopfield神经网络是一种递归神经网络，由约翰·霍普菲尔德在1982年发明。Hopfield网络是一种结合存储系统和二元系统的神经网络。它保证了向局部极小的收敛，但收敛到错误的局部极小值（local minimum），而非全局极小（global minimum）的情况也可能发生。Hopfield网络也提供了模拟人类记忆的模型。




  [1]: ./images/1502707074317.jpg
  [2]: ./images/1502707360639.jpg
  [3]: http://news.hexun.com/2016-07-04/184730214.html
  [4]: ./images/1502708940728.jpg
  [5]: ./images/1502709129286.jpg